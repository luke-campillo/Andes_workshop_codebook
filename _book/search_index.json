[["index.html", "Andes Phylogenomics Workshop Chapter 1 Getting Started", " Andes Phylogenomics Workshop Rachel Schwartz 2023-06-12 Chapter 1 Getting Started This book will walk you through "],["intro.html", "Chapter 2 Introduction 2.1 Introduction 2.2 Case Studies 2.3 Course Objectives", " Chapter 2 Introduction Syllabus of Wasta et al. 2020 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7188297/#pbio.3000667.s003 provides the following example: 2.1 Introduction Biological research is turning to genetic research methods for a deeper look into the biological factors that encode various traits. We can use genetic techniques to delimit species, define populations, understand reproductive patterns systems, and answer many other interesting biological questions. This program is set in Colombia, where students will learn how field research is conducted, participate in sample collection, and then interpret genetic data from these species to examine their relationships and understand how to accurately conduct analyses in these areas. This program will provide an introduction to next-generation sequencing technology to biologists, who will gain not only the skills requisite for field research but the technical know-how to employ genetic research tools. 2.2 Case Studies In this course, we will focus on three specific cases We will use data from 40 species in the family Campanulaceae. We will break into groups and each examine a subset of these data. We will examine different datasets using different approaches to understand how individual datasets contribute to phylogeny estimation. My notes: This tutorial steps through the basic process of analyses in evolutionary biology. We use genome sequence data to build phylogenetic trees. We then use these phylogenies and trait data to understand… 2.3 Course Objectives The goals of this course are to give participants advanced training in techniques important to the collection and analysis of plant evolution. The course has the following broad objectives: To engage in both independent and team-based data collection To teach sample collection techniques for plants Examine sequence data Build trees "],["data-and-analysis.html", "Chapter 3 Data and analysis 3.1 Genomic data 3.2 Phylogenies 3.3 Comparative analyses", " Chapter 3 Data and analysis 3.1 Genomic data By definition genomes are large. The human genome is 3.2 billion base pairs. Plants can be even larger. If you were to go through and compare two plant genomes by hand to discover the differences between them it would take a while. To add to this complexity, genomes don’t come off the sequencer as a 3.2 billion base pair sequence, but as millions of small fragments. Think of this sequencing method as tossing a book (your genome) into a paper shredder. That means first you have to compare each fragment to a “reference genome” (like the real book) and then figure out where your genome differs from the reference. This is definitely a process you don’t want to do by hand! A computer (at least a big one with lots of computing power) can help us out by automating all these comparisons. That means that before we can identify how the sequence of two plants differ we need to build some skills to communicate with the server that we are using to work with our data. 3.2 Phylogenies Different analyses produce different trees. Different datasets produce different trees. Rapid diversification makes analyses challenging. Divergence dates can be estimated on trees with calibrations. 3.3 Comparative analyses Understand models of character evolution and apply simple PCMs to existing datasets. Calculating trait evolution. "],["computational-skills.html", "Chapter 4 Computational skills 4.1 Log in to the server 4.2 Basic navigation", " Chapter 4 Computational skills The high-performance computer we’ll use for our data doesn’t have the graphical interface you usually use (like a PC or Mac). That means you have to type in your commands - you can’t point and click. This actually has a hidden benefit because it’s easy to write down what you did in a line of text rather than having to try to explain where to click on each step. Let’s start by learning how to access our server and run commands without clicking. 4.1 Log in to the server For this duration of this workshop you will have access to a server at the University of Rhode Island. Go to rstudio.uri.edu and log in with the first part of your email address as both the username and password. Click on the Terminal tab to access the command line interface. 4.2 Basic navigation To see the list of files on this computer in your “home” directory do the following: ls This folder might be empty because you haven’t put anything here. Let’s start our project by getting organized. First, you can make a directory to put your scripts in. We’ll write these scripts in a little while, but basically a script is a list of commands that you will give the computer to do all the steps to analyze your data. To make a directory you need two things - the command to make the directory and the name of that directory. mkdir scripts Now we can move into that folder. cd means change directory so we’ll use that a lot to open different folders. This command also has a command and an argument. cd scripts Now to get back to your home folder you can’t cd and give it a folder name because the computer will look in your current folder (scripts) for another folder. Instead you need to tell the computer to “move one level up”, going outside the current folder to the one containing it. cd .. To practice, repeat this process but make a directory called results. Now list the files in your current home directory again. Do you see the two folders you just made? If you want to check out what is in these folders (they are currently empty but we will add to them later) you have two options. First, you can change directory with the cd command and list the contents of the folder with ls. Think about these folder just like a filing cabinet. You started off in your home folder and now you are opening the results folder. Alternatively, list the contents of a folder by given ls the folder name as an argument (e.g. ls scripts). We will learn lots more commands as we work through our data. Adapted from http://swcarpentry.github.io/shell-novice/ "],["getting-your-data.html", "Chapter 5 Getting your data 5.1 Repeating analyses", " Chapter 5 Getting your data For this workshop we will be using genome sequence data from a group of Andean plants. For starters we will take a peak at these data so you know what it looks like before we use standard programs to analyze it. The sequence data is in a shared folder on this server. Relative to your home folder you can find the data at ../shared/AndesWorkshop2023/. If you cd to that directory and list the contents you can see folders containing files of data. Sequence files for samples can be found in different folders labeled by taxon set. Start by going to the folder for your assigned taxon set and listing its contents. You should see two folders. Go into the one for your assigned dataset. You generally do not want to view sequence data files because they can be large and are rather hard to read. If you want to see how large use ls -lh. You are already familiar with the ls command for listing the contents of folders. The dash followed by additional letters are called flags. The l flag indicates that we are listing the contents in long form to provide additional information. The h flag means we’ll view the data in human readable format (i.e. with size given in Kb or Mb). Raw data is in the form of zipped fastq files, which are generated by a sequencer. You can tell this by the very last bit of the name of the files, which is .fastq.gz or .fq.gz (just like you might see Word files labeled as .docx). Just as a note, you often need to do some cleanup of the data that comes of the sequencer so you only have high quality data. We have done this step for you already. Take a look at a little bit of one file. The less command lets you scroll through the (very large) file. zless is the less command that works on zipped files. Use the following command replacing [] with a specific filename. zless [].fastq.gz Fastq files contain sets of four lines. The first line is the name of the sequence. The second line is the sequence. The fourth line is the quality of the sequence. As you scroll through you should see many sets of four (one for each sequence). Once you are done scrolling use q (for quit) to get back to your prompt. Before we look at our large files we are going to practice on a small example file. Move back to the main AndesWorkshop2023 folder. List the contents and notice the example.fq file. For this example I have unzipped it. You can view the entire contents of the file using the command cat. cat example.fastq Alternatively you can use the command head to view the first few lines of the file. head example.fq We can also get a sense of the amount of data by counting the number of lines using the word count command wc. wc example.fq This command tells you the number of lines, words, and characters. If you want to focus just on the number of lines you should use the l flag. wc -l example.fq If we only want to get the names of the sequences we can search for lines that match a particular pattern and print just those. We search with the command grep. The pattern we are searching for is lines that start with @. And then we provide the name of the file. grep &#39;^@&#39; example.fq Because this is a small example file we are able to print all the header lines without it being overwhelming. However, with our larger files we don’t want to do this. However, we know that the head command allows us to view just the first few lines of our output. Now we’ll combine those two commands using a pipe (|). First we enter the grep command (with it’s two arguments) then we “pipe” the output to the head command rather than printing it to the screen. grep &#39;^@&#39; example.fastq | head Notice that the head command does not have arguments in this case because it accepts the output from the grep command. The head command accepts a flag with the number of lines you want to print. For example head -4 will print the first four lines. Your first challenge in this course is to combine the information that you have learned to get the number of header lines in one of your zipped fastq files (using zgrep). 5.1 Repeating analyses One approach to analyzing multiple files in the same way is to copy your code and edit each copy to include the name of a particular file. That might be feasible (if slow) for the 10 files you are working with here, but it is inconvenient for the many files you might work with on a larger genomics project. Instead, we can make a list of the files we want to work with and tell the computer to repeat the analysis on each file. In the prior challenge you figured out what analysis you want to do (list the number of header lines). Now we need to learn how to repeat this. In most programming languages, including our command line, we use a loop to go through a list and repeat that command. On the command line the format to do this looks like for thing in list_of_things do command $thing done We start with for to indicate that we are about to make a loop. Each time the loop runs (called an iteration), an item in the list is assigned in sequence to the variable thing, and the commands inside the loop are executed. Think of a variable as a box that holds the item we are working with. For example, if we are working with a list of files then the first time through the loop thing is the first file name in the list, the second time through thing is the second name, and so on. This allows us to repeat our command for each item in the list using the same variable name. Inside the loop, we indicate the variable by putting $ in front of it. The $ tells the shell interpreter to treat the variable as a variable name and substitute its value in its place, rather than treat it as text or an external command. Start by figuring out what goes on the third line of the loop Now figure out what goes on the first line (i.e. your list) When you run your loop it should print the number of header lines for each file We might want to add one command to this loop to print out the name of the file prior to printing the number of header lines so we can more easily keep track of each file’s information. The echo command will print whatever comes after it. Try inserting this command into your loop in order to print the name of the file following by the number of header lines. Did you need to list all your files by hand? Copying and pasting a lot of names can be time consuming and error prone. Logically, you want to make your list following a particular rule, for example all of the files in this folder. We can use a wildcard (denoted *) to do this. So instead of writing out all the file names, replace all of that just with * as your list. In other situations keep in mind that we might want to be more precise. * really suggests any number of any character. To indicate all files that end in fastq.gz we could use *fastq.gz as our list. "],["target-capture-data.html", "Chapter 6 Target capture data 6.1 Visual inspection of data (eg, alignment, BLAST)", " Chapter 6 Target capture data Much of the information in this chapter is drawn from the HybPiper tutorial, which can be found at https://github.com/mossmatters/HybPiper/wiki/Tutorial First make a folder in your home directory to hold your outputs for this component of the project. We have pre-installed the program HybPiper, which assembles target sequences from high-throughput DNA sequencing reads. To access HybPiper run conda activate /mnt/homes4celsrs/shared/envs/hybpiper In this case, our target sequences are the Angiosperm 353 standard targets. Target capture is a standard technique for sequencing many known loci simultaneously using a library of sequences. We have provided you with low-coverage sequence data from using these target sequences as probes (your fastq files). HybPiper first assigns each read to a particular target using alignment software (BWA). These reads are then assembled using a standard genome assembler (Spades). HybPiper outputs a fasta file of the (in frame) CDS portion of each sample for each target region. The basic command for HybPiper is as follows: hybpiper assemble -t_dna targets.fasta -r species1_R*_test.fastq --prefix species1 --bwa --cpu 2 You should run this command, changing the file starting with “species1” to the name of one of your files, which you can find by listing the files in the folder of your data. Note the * indicates that we will use both pairs of the sequencing read files. Also change the prefix to something relevant for this species. Note that we are sharing a server so we are specifying 2 cpu’s per group - if you are running on your own machine you can omit this flag and HybPiper will use all available resources. To automatically run all samples consecutively you will need to loop through them. One approach is to make a list of all the names of the species in a file and then read that and use them one at a time. First we need to make the list. We want to automate this process because in some cases you could have a lot of samples. Additionally, copying and pasting names into a list is prone to error. Plus once you automate this process you could repeat it easily and quickly for other datasets. For starters make a list of just the R1 files (you don’t want R2 files because they have the same name so you would have duplicates) and output this to a file (name it namelist.txt). Really, we don’t want such long names, plus this includes R1 alone and we want to be able to list both files together. One approach is to notice a pattern in filenames: the files start with a sample identifier followed by an underscore followed by another identifier. Thus, we can “cut off” all of the name after the second underscore and still have a unique name for our sample. We use the “cut” command to make our data into columns using _ (specify a delimiter with -d), then we select the first two of these (use the field flag -f). ls *R1* | cut -d &#39;_&#39; -f 1,2 &gt;namelist.txt You can check this worked by viewing the file and counting the number of lines. Now we can run HybPiper on all of our data sequentially. In the following example, the species names are entered in the namelist.txt file. The loop will iterate through them one at a time and run HybPiper. while read name do hybpiper assemble -t_dna ../../Campanulaceae_353.fasta -r ${name}*fq.gz --prefix $name \\ --bwa --cpu 2 done &lt; namelist.txt hybpiper stats -t_dna ../../Campanulaceae_353.fasta gene namelist.txt From https://hackmd.io/@mossmatters/HkPM7pwEK#Getting-HybPiper-Stats *hybpiper stats will generate two files, seq_lengths.tsv and hybpiper_stats.tsv The first line of seq_lengths.tsv has the names of each gene. The second line has the length of the target gene, averaged over each “source” for that gene. The rest of the lines are the length of the sequence recovered by HybPiper for each gene. If there was no sequence for a gene, a 0 is entered.* At this point, each sequence is in its own folder. We can use HybPiper to fetch the sequences recovered for the same gene from multiple samples and generate a file for each gene. Use the following command, hybpiper retrieve_sequences dna -t_dna ../../Campanulaceae_353.fasta --sample_names namelist.txt Note that HybPiper has additional features we will not use in this workshop due to a lack of time. 6.1 Visual inspection of data (eg, alignment, BLAST) "],["plastome-variation.html", "Chapter 7 Plastome variation", " Chapter 7 Plastome variation We will use the program GetOrganelle to assemble and plastome for each species from the genome skimming data we have looked at previously. Note that to improve analytical speed we have pre-examined and filtered data for you. The data we will work with for chloroplasts can be found in….. get_organelle_from_reads.py -1 species1.1.fq.gz -2 species1.2.fq.gz -t 1 -o species1.plastome -F embplant_pt -R 10 #do all #pull all plastomes in one fasta allspecies.fasta mauveAligner --output=allspecies.mauve --output-alignment=allspecies.alignment allspecies.fasta "],["variant-calling.html", "Chapter 8 Variant Calling", " Chapter 8 Variant Calling First make a folder in your home directory to hold your aligned files. mkdir alignment Now we need to run the program to figure out which reads come from the chloroplast genome by comparing the reads to a reference. This is called aligning. However, before we do this, we have to recognize that this process might take a while. Let’s start by making a file that contains our command, which we’ll call a script. nano scripts/alignment_script.sh See how I made my script inside the scripts folder to keep everything organized? That .sh on the end also says something about this file - in this case it is a script that can be run in our computing “shell”. Let’s add the command we need to run to our script bowtie2 -x [ref] -1 []R1_001.fastq.gz -2 []R2_001.fastq.gz -S results/[].sam What does this command mean? First we have bowtie2, which is the name of the program we are using. Then we have a series of “flags” (they start with -) followed by some information. The -x flag says what reference genome we want to align to. That’s going to be in [] and its name is [hg38]]. Now we list the path to our fastq sequence files with the -1 and -2 flags. And finally we use the -S flag to say where we want our output to go. This file has a .sam extension because that’s what the makers of this program have called this output file format. You need to tell the computer that this is a “shell” script. The first line of every script has a “shebang” line that specifies how the computer should interpret the code. #!/bin/sh Exit nano with Ctrl-X and save your script. Now you can tell the computer to run the script. bash scripts/alignment_script.sh Now make a copy of the script `cp scripts/alignment_script.sh scripts/alignment_script2.sh`` See how the copy command (cp) takes two arguments: the source and destination. [LOOP] Run this script. Now you can take a look at one of your output sam files using less. Type q to go back to your prompt. This file is in a special format with a lot of information about where each read came from in the reference genome and also how well it aligned to that location. Before we look more closely, did you notice that you are scrolling through a lot of header information before you got to any real data? You can ask the computer to search for and only print files that aren’t header lines. Header lines start with @SQ so that’s what we’ll have the computer print - anything that matches that pattern. We also need to specify we want lines that don’t start with @SQ. If you are searching for lines that start with @SQ you need that information plus the code for “starts with”, which is ^. Finally you need to specify you want the opposite lines, so you’ll use a “flag” -v. Then you’ll need to add the file name as an argument. Here’s the command but don’t type it yet! This will print out a ton of data. grep -v '^@SQ' results/[].sam You can use this command but make sure to pipe the output to less so you can scroll through it. There’s a lot of information here but don’t worry too much about the details. Each line is just information about where that sequence aligned to the human genome and how well it aligned. These alignments allow other programs to figure out what the sequence is for each base in each individual. These files are rather large, but we can compress them into bam format, which makes them take less space and also makes them easier to work with. You can convert a sam file to a bam file using the following command. samtools view -b -o results/U0a_CGATGT_L001_001_mapped.bam results/U0a_CGATGT_L001_001.sam Rather than type this on the command line (where you will forget what you typed and it won’t work right anyway), make a new script with this command instead of the bowtie command. I advise copying the alignment script (give it a useful name) and put this command in place of the bowtie line. Also add this samtools view command for your other files so that you have 11 lines that look similar except for the input and output filenames. Did you notice how this command has flags and arguments (output then input files) just like other command line commands? The program samtools is a set of tools for working with sam files. The view command loads the file. The o flag sets the name of the output file. The b flag outputs in bam format. All the samtools commands and flags can be found at http://www.htslib.org/doc/samtools.html Once all of your alignment scripts are done running, run this script to convert sams to bams. Adapted from https://datacarpentry.org/wrangling-genomics/ At this point you have aligned the sequencing reads to the reference genome. Your sam/bam file tells you where each read belongs. The next step is to go through each base in the genome and figure out what base is at that position in each of your individuals. “The last step in preparing the reads is to index the bam files. This needs to be done to enable fast access to reads overlapping a given position of the genome. Without the index, if you wanted to access reads at the beginning of chromosome 20, you’d need to read through chromosomes 1-19 until you got there. With many samples or deep coverage, this would be a big problem. The bam index is a map to the bam file that lets you skip around quickly.” sort first?? samtools index results/*.bam TVIEW?? Pileup call https://genome.sph.umich.edu/wiki/Triodenovo https://www.youtube.com/watch?v=wzjhhUaErWc https://github.com/ekg/alignment-and-variant-calling-tutorial https://gencore.bio.nyu.edu/variant-calling-pipeline-gatk4/ https://github.com/CBC-UCONN/Variant-Calling "],["results.html", "Chapter 9 Results 9.1 Alignment 9.2 View in R 9.3 Trimal 9.4 Concatenated data analysis 9.5 Species tree analyses 9.6 Support for relationships 9.7 What does your tree tell you?", " Chapter 9 Results 9.1 Alignment In order to use these data to build our phylogenies, we need to align each gene. This allows our tree-building software to compare species using nucleotides that we believe share ancestry. We will use the software MAFFT. Due to the nature of this server different programs are in different “environments” so you’ll need to deactivate the hybpiper environment and activate one for mafft. conda deactivate conda activate /mnt/homes4celsrs/shared/envs/mafft Now MAFFT is available to run. Note that we are looping through each of the data files (one per gene) generated by HybPiper and outputting an alignment. The basic mafft command looks like the following, assuming you replace FILE with a particular file. mafft --auto --thread 1 FILE &gt; FILE.fasta for f in *fasta; do cut -f 1 -d &#39; &#39; $f &gt; ${f}.fa done However, you should be able to loop through all of your files output by HybPiper so that you can align all of them sequentially in one loop command. 9.2 View in R library(ggmsa) #use R 4.1.2 #view aligned tax1_seqs_4471 &lt;- (&quot;AndesWorkshop2023/TaxonSet1/353reads/4471.FNA.fasta.fa&quot;) ggmsa(tax1_seqs_4471, start = 20, end = 120, char_width = 0.5, seq_name = T, color = &quot;Chemistry_NT&quot;) + geom_msaBar() #this is slow - wait! #view unaligned tax1_seqs_4471u &lt;- (&quot;AndesWorkshop2023/TaxonSet1/353reads/4471.FNA&quot;) ggmsa(tax1_seqs_4471u, start = 20, end = 120, char_width = 0.5, seq_name = T, color = &quot;Chemistry_NT&quot;) + geom_msaBar() #this is slow - wait! 9.3 Trimal https://hackmd.io/@mossmatters/Sy6md0prY 9.4 Concatenated data analysis There are multiple ways to analyze data. The first is to concatenate everything. conda deactivate conda activate /mnt/homes4celsrs/shared/envs/amas python3 /mnt/homes4celsrs/shared/envs/amas/bin/AMAS.py concat -f fasta \\ -d dna --out-format fasta --part-format raxml -i *FNA.fasta.fa \\ -t concatenated.fasta -p partitions.txt Note that if some data was not found for some genes you may need to delete files to get AMAS to concatenate your data. 9.4.1 Building trees with IQTree We will build our first tree using our complete concatenated dataset. The program IQtree infers phylogenetic trees by maximum likelihood. This approach starts with a tree and calculates the likelihood of the data on the tree (i.e. calculating the probability of each site fitting the tree given a model of substitution and multiplying them together). We use the General Time Reversible (GTR) model to allow sites to change back and forth among different bases with particular probabilities. We also allow a Gamma (G) distribution of rates of substitution across sites. We allow partitioning of the data by gene so that different genes can evolve according to different models. conda deactivate conda activate /mnt/homes4celsrs/shared/envs/iqtree iqtree2 -nt 2 -s concatenated.fasta -spp partitions.txt -pre iqtree_tree -B 1000 -m GTR+G Tree for all data using output of individual hybpiper runs 9.4.2 Viewing trees Make new RScript library(tidyverse) library(ape) tax1 &lt;- read.tree(&quot;AndesWorkshop2023/TaxonSet1/353reads/iqtree_tree.treefile&quot;) plot(tax1, show.node.label = TRUE) 9.4.3 svdq echo &quot; log file=${logFile}; tonexus format=RelPHYLIP fromfile=concatenated.fasta tofile=concatenated.svdq.nex \\ interleaved=yes replace=yes; exe concatenated.svdq.nex; svdq bootstrap nreps=1000 nthreads=2; saveTrees file=concatenated.svdq; quit; &quot; | paup 9.4.4 MrBayes 9.5 Species tree analyses An alternative is to use a species tree approach. 9.5.1 ASTRAL #gene trees from iqtree #astral 9.6 Support for relationships 9.6.1 Bootstrap 9.6.2 SCF / GCF iqtree2 -t tree.tre -s concatenated.fasta --scf 100 --prefix SCF -nt 2 9.7 What does your tree tell you? Compare your trees "],["sharing-your-results.html", "Chapter 10 Sharing your results 10.1 Presentation", " Chapter 10 Sharing your results 10.1 Presentation Slides on your study group. Don’t forget to convince your uninformed audience that this is the most fascinating group in the world with lots to help up understand about evolution. Slides on the information that isn’t known about this group - i.e. the question you will answer. Make sure we’re convinced that the question you answer will help us address all those cool questions you raised in 1. Your methods - briefly. Describe the approach, not the steps you take on the computer. Talk about methods, not software. Your tree. Highlight new information. Conclusions. What implications do your results have for evolutionary biology? Tips: https://research.usu.edu/undergradresearch/oral-presentations/ Great example: https://www.youtube.com/watch?v=fZ0NzM6g7jk "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
